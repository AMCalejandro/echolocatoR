% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/MAIN.R
\name{finemap_pipeline}
\alias{finemap_pipeline}
\title{Run \pkg{echolocatoR} pipeline on a single locus}
\usage{
finemap_pipeline(
  locus,
  fullSS_path,
  fullSS_genome_build = "hg19",
  LD_genome_build = "hg19",
  results_dir,
  dataset_name = "dataset_name",
  dataset_type = "GWAS",
  top_SNPs = "auto",
  force_new_subset = F,
  force_new_LD = F,
  force_new_finemap = T,
  finemap_methods = c("ABF", "FINEMAP", "SUSIE", "POLYFUN_SUSIE"),
  finemap_args = NULL,
  bp_distance = 5e+05,
  n_causal = 5,
  chrom_col = "CHR",
  chrom_type = NULL,
  position_col = "POS",
  snp_col = "SNP",
  pval_col = "P",
  effect_col = "Effect",
  stderr_col = "StdErr",
  tstat_col = "t-stat",
  locus_col = "Locus",
  freq_col = "Freq",
  MAF_col = "MAF",
  A1_col = "A1",
  A2_col = "A2",
  gene_col = "Gene",
  N_cases_col = "N_cases",
  N_controls_col = "N_controls",
  N_cases = NULL,
  N_controls = NULL,
  proportion_cases = "calculate",
  sample_size = NULL,
  LD_reference = "1KGphase1",
  superpopulation = "EUR",
  remote_LD = T,
  download_method = "direct",
  min_POS = NA,
  max_POS = NA,
  min_MAF = NA,
  trim_gene_limits = F,
  max_snps = NULL,
  file_sep = "\\t",
  min_r2 = 0,
  LD_block = F,
  LD_block_size = 0.7,
  vcf_folder = NULL,
  query_by = "coordinates",
  remove_variants = F,
  remove_correlates = F,
  probe_path = "./Data/eQTL/gene.ILMN.map",
  conditioned_snps,
  plot_LD = F,
  remove_tmps = T,
  plot.types = c("simple"),
  PAINTOR_QTL_datasets = NULL,
  server = F,
  PP_threshold = 0.95,
  consensus_threshold = 2,
  case_control = T,
  QTL_prefixes = NULL,
  fillNA = 0,
  plot.zoom = "1x",
  plot.Nott_epigenome = F,
  plot.Nott_show_placseq = F,
  plot.Nott_binwidth = 200,
  plot.Nott_bigwig_dir = NULL,
  plot.XGR_libnames = NULL,
  plot.Roadmap = F,
  plot.Roadmap_query = NULL,
  conda_env = "echoR",
  nThread = 4,
  verbose = T
)
}
\arguments{
\item{fullSS_path}{Path to the full summary statistics file (GWAS or QTL) that you want to fine-map.
It is usually best to provide the absolute path rather than the relative path.}

\item{results_dir}{Where to store all results.
\strong{IMPORTANT!:} It is usually best to provide the absolute path rather than the relative path.
This is especially important for \emph{FINEMAP}.}

\item{dataset_name}{The name you want to assign to the dataset being fine-mapped,
This will be used to name the subdirectory where your results will be stored
(e.g. \emph{Data/GWAS/<dataset_name>}).
Don't use special characters (e.g.".", "/").}

\item{dataset_type}{The kind dataset you're fine-mapping (e.g. GWAS, eQTL, tQTL).
This will also be used when creating the subdirectory where your results will be stored
(e.g. \emph{Data/<dataset_type>/Kunkle_2019}).}

\item{top_SNPs}{A data.frame with the genomic coordinates of the lead SNP for each locus.
The lead SNP will be used as the center of the window when extracting subset from the full GWAS/QTL summary statistics file.
Only one SNP per \strong{Locus} should be included.
At minimum, \code{top_SNPs} should include the following columns:
\describe{
\item{\emph{Locus}}{A unique name for each locus. Often, loci are named after a relevant gene (e.g. LRRK2) or based on the name/coordinates of the lead SNP (e.g. locus_chr12_40734202) }
\item{\emph{CHR}}{The chromosome that the SNP is on. Can be "chr12" or "12" format.}
\item{\emph{POS}}{The genomic position of the SNP (in basepairs)}
}}

\item{force_new_subset}{By default, if a subset of the full summary stats file for a given locus is already present,
then \pkg{echolocatoR} will just use the pre-existing file.
Set \code{force_new_subset=T} to override this and extract a new subset.
Subsets are saved in the following path structure:
\emph{Data/<dataset_type>/<dataset_name>/<locus>/Multi-finemap/<locus>_<dataset_name>_Multi-finemap.tsv.gz}}

\item{force_new_LD}{By default, if an LD matrix file for a given locus is already present,
then \pkg{echolocatoR} will just use the preexisting file.
Set \code{force_new_LD=T} to override this and extract a new subset.}

\item{force_new_finemap}{By default, if an fine-mapping results file for a given locus is already present,
then \pkg{echolocatoR} will just use the preexisting file.
Set \code{force_new_finemap=T} to override this and re-run fine-mapping.}

\item{finemap_methods}{Which fine-mapping methods you want to use.}

\item{bp_distance}{The width of the window size you want each locus to be.
For example, if \code{bp_distance=500000} then the locus will span 500kb from the lead SNP in either direction,
resulting in a locus that is ~1Mb long (depending on the dataset).}

\item{n_causal}{The maximum number of potential causal SNPs per locus.
This parameter is used somewhat differntly by different fine-mapping tools.
See tool-specific functions for details.}

\item{chrom_col}{Name of the chromosome column in the full summary stats file.
Can be "chr1" or "1" format.
(\emph{default: ="CHR"})}

\item{position_col}{Name of the genomic position column in the full summary stats file.
Must be in units of basepairs.
(\emph{default: ="POS"})}

\item{snp_col}{Name of the SNP RSID column in the full summary stats file.
(\emph{default: ="SNP"})}

\item{pval_col}{Name of the p-value column in the full summary stats file.
Raw p-values are preferred, but if not available corrected p-values (e.g. FDR) can be used instead.
(\emph{default: ="P"})}

\item{effect_col}{Name of the effect size column in the full summary stats file.
Effect size is preferred, but if not available other metrics like Beta for Odds Ratio can be used instead.
(\emph{default: ="Effect"})}

\item{stderr_col}{Name of the standard error  column in the full summary stats file.
You can also set \code{stderr_col="calculate"} to infer standard error using: \code{effect / tstat}.
(\emph{default: ="StdErr"})}

\item{tstat_col}{Name of the t-statistic column in the full summary stats file.
This column is not necessary unless \code{stderr_col="calculate"} or the standard error column is missing.
(\emph{default: ="t-stat"})}

\item{locus_col}{Name of the locus column in the full summary stats file.
(\emph{default: ="Locus"})}

\item{freq_col}{Name of the allele frequency column in the full summary stats file.
Effect allele frequency is preferred, but the non-effect allele can be provided instead (though this may be less accurate).
This column is not necessary unless \code{MAF_col="calculate"} or the MAF column is missing.
(\emph{default: ="Freq"})}

\item{MAF_col}{Name of the minor allele frequency column in the full summary stats file.
Can be inferred from \strong{freq_col} if missing from the dataset.
(\emph{default: ="MAF"})}

\item{A1_col}{Name of the effect/risk allele column in the full summary stats.
 \strong{\emph{IMPORTANT}}: Make sure this actually the case for your full summary stats file.
Unfortunately, different studies report different kinds of allele information in a non-standardized way.
Meaning that A1/A2 can refer to any number of things:
 \describe{
 \item{effect/other alleles}{in the case of diseases}
 \item{ref/alt alleles}{where ref is the reference genome being used}
 \item{major/minor alleles}{This dichotomy holds true for bi-allelic SNPs but not necessary multi-allelic SNPs}
 }
 This makes comparing summary stats across GWAS/QTL datasets very confusing for several reasons:
 \describe{
 \item{Multi-allelic SNPs}{SNPs can have more than just 2 possible alleles (multi-allelic SNPs). Even if you compare the same SNP between two studies, you may accidentally be comparing totally different alleles.}
 \item{Valence}{The valence (+/-) of per-SNP GWAS effect sizes/beta can be relative to different allele types between studies.
 For example, let's say in one GWAS study your effect size for SNP A is 1.5 relative to the major allele in one study,
  and the minor allele happens to be the one found in the reference genome.
  You then try to compare that effect size to that of the same SNP in another GWAS.
  But, the valence of the effect sizes in the 2nd GWAS study are all relative to the reference genome (instead of the minor allele),
  giving the same SNP a value of -1.2. If you took the effect sizes at face value you'd say the signals are in opposite directions.
  But once you take into account how the valences were determined in each study you realize that they're actually both positive relative to the major allele.}
 }
This process of reversing per-SNP valences based on aligning the alleles is known as allele flipping.
This is important when comparing individual SNPs, but can also have an impact on colocalization results.}

\item{gene_col}{For QTL studies, the name of the [e]gene column in the full summary stats file (\emph{default: "gene"}).
This column will be used for filtering summary stats if supplying a named list of gene:Locus pairs to \code{loci}.}

\item{N_cases_col}{Name of the column in the full summary stats that has the number of case subjects in the study.
This can either be per SNP sample sizes, or one number repeated across all rows.
Proxy cases (e.g. relatives of people with the disease being investigated) should be included in this estimate if any were used in the study.
This column is not necesssary if \code{N_cases} parameter is provided.
(\emph{default: ="N_cases"})}

\item{N_controls_col}{Name of the column in the full summary stats that has the number of control subjects in the study.
 This can either be per SNP sample sizes, or one number repeated across all rows.
 This column is not necesssary if \code{N_controls} parameter is provided.
(\emph{default: ="N_controls"})}

\item{N_cases}{The number of case subjects in the study.
Instead of providing a redundant \strong{N_cases_col} column, you can simply enter one value here.}

\item{N_controls}{The number of control subjects in the study.
Instead of providing a redundant \strong{N_controls_col} column, you can simply enter one value here.}

\item{proportion_cases}{The proportion of total subjects in the study that were cases.
if \code{proportion_cases="calculate"} then this is inferred:  \code{N_controls / N_controls}.}

\item{sample_size}{The overall sample size of the study.
If none is given, and \strong{N_cases} and \strong{N_controls} columns are present,
then sample_size is inferred to be:  \code{max(N_cases) + max(N_controls)}.}

\item{LD_reference}{Which linkage disequilibrium reference panel do you want to use.
Options include:
\describe{
\item{"UKB"}{A pre-caclulated LD reference matrix from a subset of caucasian British individuals from the UK Biobank. See \href{https://www.biorxiv.org/content/10.1101/807792v2}{Wiessbrod et al. (2019)} for more details.}
\item{"1KGphase1"}{Download a subset of the 1000 Genomes Project Phase 1 vcf and calculate LD on the fly with plink.}
\item{"1KGphase3"}{Download a subset of the 1000 Genomes Project Phase 3 vcf and calculate LD on the fly with plink.}
\item{"<path>/*.vcf" or "<path>/*.vcf.gz"}{Alternatively, users can provide their own custom panel by supplying a list of \emph{.vcf} file path (one per locus) which \pkg{echolocatoR} will use to compute LD (using \emph{plink}).}
}}

\item{superpopulation}{Subset your LD reference panel by superopulation.
Setting the superpopulation is not currently possible when \code{LD_reference="UKB"}.
\href{https://www.internationalgenome.org/faq/which-populations-are-part-your-study/}{1KGphase1 options} include:
\describe{
\item{"AFR"}{African [descent]}
\item{"AMR"}{Ad-mixed American}
\item{"EAS"}{East Asian}
\item{"EUR"}{European}
\item{"SAS"}{South Asian}
}}

\item{remote_LD}{When acquiring LD matrixes,
the default is to delete the full vcf or npz files after \pkg{echolocatoR} has extracted the necssary subset.
However, if you wish to keep these full files (which can be quite large) set \code{remote_LD=T}.}

\item{min_POS}{Manually set the minimum genomic position for your locus subset.
\code{min_POS} can clip the window size set by \code{bp_distance}.
Can also be a list of positions (one for each locus) (e.g. \code{min_POS=top_SNPs$min_POS}).}

\item{max_POS}{Manually set the maximum genomic position for your locus subset.
\code{max_POS} can clip the window size set by \code{bp_distance}.
Can also be a list of positions (one for each locus) (e.g. \code{max_POS=top_SNPs$max_POS}).}

\item{min_MAF}{Remove any SNPs with \strong{MAF} < \code{min_MAF}.}

\item{trim_gene_limits}{If a valid gene symbol is provided to \code{trim_gene_limits},
the gene's canonical coordinates are pulled from \code{biomaRt}.
This includes introns, exons, and proximal regulatory regions (e.g. promoters).
Any SNPs that fall outside these coordinates are remove from downstream fine-mapping.
Set \code{trim_gene_limits=F} to not limit by gene coordinates (\emph{default}).}

\item{max_snps}{The maximum number of SNPs to include in the locus.
If the current window size yields > \code{max_snps},
 then the outer edges of the of the locus are trimmed until the number of SNPs ≤ \code{max_snps}.}

\item{file_sep}{The separator in the full summary stats file.
This parameter is only necessary if \code{query_by!="tabix"}.}

\item{min_r2}{Remove any SNPs are below the LD r2 threshold with the lead SNP within their respective locus.}

\item{LD_block}{Calculate LD blocks with \emph{plink} and only include the block to which the lead SNP belongs.}

\item{LD_block_size}{Adjust the granularity of block sizes when \code{LD_block=T}.}

\item{query_by}{Choose which method you want to use to extract locus subsets from the full summary stats file.
Methods include:
\describe{
\item{"tabix"}{Convert the full summary stats file in an indexed tabix file. Makes querying lightning fast after the initial conversion is done. (\emph{default})}
\item{"coordinates"}{Extract locus subsets using min/max genomic coordinates with \emph{awk}.}
}}

\item{remove_variants}{A list of variants to remove from the locus subset file.}

\item{remove_correlates}{A named list, where the names are the RSIDs of SNPs
whose LD correlates you wish to remove,
and the value is the absolute r2 threshold you wish to filter at for each RSID respectively
(e.g. \code{ remove_correlates = c("rs76904798"=.2, "rs10000737"=.8)}).
This will also remove the SNPs in \code{remove_correlates} themselves.}

\item{probe_path}{The location of the file containing translations between probe IDs and gene symbols.
Only used for certain eQTL datasets.}

\item{conditioned_snps}{Which SNPs to conditions on when fine-mapping with \emph{COJO}.}

\item{plot_LD}{Whether to plot a subset of the LD matix.}

\item{remove_tmps}{Whether to remove any temporary files (e.g. FINEMAP output files) after the pipeline is done running.}

\item{plot.types}{Which kinds of plots to include.
Options:
\describe{
\item{"simple"}{Just plot the following tracks: GWAS, fine-mapping, gene models}
\item{"fancy"}{Additionally plot XGR annotation tracks (XGR, Roadmap, Nott).}
}}

\item{PAINTOR_QTL_datasets}{A list of QTL datasets to be used when conducting joint functional fine-mapping with \emph{PAINTOR}.}

\item{server}{Whether \pkg{echolocatoR} is being run on a computing cluster/server or on a local machine.}

\item{PP_threshold}{The minimum fine-mapped posterior probability for a SNP to be considered part of a Credible Set.
For example, \code{PP_threshold=.95} means that all Credible Set SNPs will be 95\% Credible Set SNPs.}

\item{consensus_threshold}{The minimum number of fine-mapping tools that include a SNP
in their 95\% Credible Sets to consider that it a "Consensus SNP" (\emph{default=2}).}

\item{plot.zoom}{Zoom into the center of the locus when plotting (without editing the fine-mapping results file).
You can provide either:
\itemize{
\item{The size of your plot window in terms of basepairs (e.g. \code{plot.zoom=50000} for a 50kb window)}.
\item{How much you want to zoom in (e.g. \code{plot.zoom="1x"} for the full locus, \code{plot.zoom="2x"} for 2x zoom into the center of the locus, etc.)}.
}
You can pass a list of window sizes (e.g. \code{c(50000,100000,500000)}) to automatically generate
multiple views of each locus.
This can even be a mix of different style inputs: e.g. \code{c("1x","4.5x",25000)}.}

\item{plot.Nott_binwidth}{When including Nott et al. (2019) epigenomic data in the track plots,
adjust the bin width of the histograms.}

\item{plot.Nott_bigwig_dir}{Instead of pulling Nott et al. (2019) epigenomic data
from the \emph{UCSC Genome Browser}, use a set of local bigwig files.}

\item{plot.Roadmap}{Find and plot annotations from Roadmap.}

\item{plot.Roadmap_query}{Only plot annotations from Roadmap whose metadata contains a string or any items from  a list of strings
(e.g. \code{"brain"} or \code{c("brain","liver","monocytes")}).}

\item{conda_env}{The name of a conda environment to use.}

\item{verbose}{Whether \pkg{echolocatoR} should be verbose or silent.}

\item{loci}{Character list of loci in \strong{Locus} col of \code{top_SNPs}.}

\item{min_Dprime}{Remove any SNPs are below the LD D' threshold with the lead SNP within their respective locus.
This is paramter currently only works when \code{LD_reference!="UKB"}.}
}
\description{
Unlike \code{finemap_loci}, you don't need to provide a \code{top_SNPs} data.frame.
Instead, just manually provide the coordinates of the locus you want to fine-map.
}
\details{
The primary functions of \pkg{echolocatoR} that expedite fine-mapping
 by wrapping many other \pkg{echolocatoR} functions into one.
 Encompasses steps including:
 \describe{
 \item{Subset & standardize}{Extract subsets of the full summmary stats GWAS or QTL file and reformat them to be compatible with \pkg{echolocatoR}'s various functions }
 \item{Calculate linkage disequilibrium}{Download and prepare the necessary LD matrix.}
 \item{Fine-map}{Run various fine-mapping tools and merge the results into a single multi-finemap data.frame.}
 \item{Plot}{Summarise the results in a multi-track plot for each locus.}
 }
}
\section{input file parameters}{

}

\section{input file column names}{

}

\section{overwrite existing files}{

}

\section{fine-mapping parameters}{

}

\seealso{
Other MAIN: 
\code{\link{finemap_loci}()}
}
\concept{MAIN}
